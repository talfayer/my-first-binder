{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4d684172-4b94-42cf-bda2-e11952420d86",
      "metadata": {
        "id": "4d684172-4b94-42cf-bda2-e11952420d86"
      },
      "source": [
        "# Homework 10\n",
        "#### Course Notes\n",
        "**Language Models:** https://github.com/rjenki/BIOS512/tree/main/lecture17  \n",
        "**Unix:** https://github.com/rjenki/BIOS512/tree/main/lecture18  \n",
        "**Docker:** https://github.com/rjenki/BIOS512/tree/main/lecture19"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d839a5ba-62f4-4699-baea-018afda70786",
      "metadata": {
        "id": "d839a5ba-62f4-4699-baea-018afda70786"
      },
      "source": [
        "## Question 1\n",
        "#### Make a language model that uses ngrams and allows the user to specify start words, but uses a random start if one is not specified."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ef37d3a-a6ad-42ae-9e16-7d7338c9ce49",
      "metadata": {
        "id": "9ef37d3a-a6ad-42ae-9e16-7d7338c9ce49"
      },
      "source": [
        "#### a) Make a function to tokenize the text."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "install.packages(\"tokenizers\")\n",
        "install.packages(\"stringr\")\n",
        "install.packages(\"httr\")\n",
        "library(tokenizers)\n",
        "library(stringr)\n",
        "library(httr)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AICr0LOkXi4u",
        "outputId": "8be8c908-6c03-4a28-ed63-4e3acb15b612"
      },
      "id": "AICr0LOkXi4u",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependency ‘SnowballC’\n",
            "\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenize_text <- function(text) {\n",
        "  # Use the tokenizer package for robust tokenization\n",
        "  tokenizers::tokenize_words(text, lowercase = TRUE, strip_punct = TRUE)[[1]]\n",
        "}"
      ],
      "metadata": {
        "id": "9-UmrnP9T31P"
      },
      "id": "9-UmrnP9T31P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "86145513-294b-4894-a02c-8ae60e2c616e",
      "metadata": {
        "id": "86145513-294b-4894-a02c-8ae60e2c616e"
      },
      "source": [
        "#### b) Make a function generate keys for ngrams."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We'll represent an (n-1)-gram context as a single string key joined by a sentinel separator.\n",
        ".key_sep <- \"\\x1f\"\n",
        "\n",
        "key_from_ngram <- function(ngram, sep = .key_sep) {\n",
        "  paste(ngram, collapse = sep)\n",
        "}\n"
      ],
      "metadata": {
        "id": "JgSx6kU9T9ox"
      },
      "id": "JgSx6kU9T9ox",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "52988c2c-b230-467f-b519-72bc85b93b43",
      "metadata": {
        "id": "52988c2c-b230-467f-b519-72bc85b93b43"
      },
      "source": [
        "#### c) Make a function to build an ngram table."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# n-gram table stored as an environment: key -> named integer vector of next-word counts\n",
        "build_ngram_table <- function(tokens, n, sep = .key_sep) {\n",
        "  if (length(tokens) < n) return(new.env(parent = emptyenv()))\n",
        "  tbl <- new.env(parent = emptyenv())\n",
        "\n",
        "  for (i in seq_len(length(tokens) - n + 1L)) {\n",
        "    context <- tokens[i:(i + n - 2L)]     # (n-1)-gram\n",
        "    next_w  <- tokens[i + n - 1L]         # the nth word\n",
        "    key     <- paste(context, collapse = sep)\n",
        "\n",
        "    counts <- if (!is.null(tbl[[key]])) tbl[[key]] else integer(0)\n",
        "    if (next_w %in% names(counts)) {\n",
        "      counts[[next_w]] <- counts[[next_w]] + 1L\n",
        "    } else {\n",
        "      counts[[next_w]] <- 1L\n",
        "    }\n",
        "    tbl[[key]] <- counts\n",
        "  }\n",
        "  attr(tbl, \"n\") <- as.integer(n)\n",
        "  attr(tbl, \"sep\") <- sep\n",
        "  tbl\n",
        "}"
      ],
      "metadata": {
        "id": "U_SfbAzrUCyD"
      },
      "id": "U_SfbAzrUCyD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "1ca6db37-abce-4705-9784-e1b898174f00",
      "metadata": {
        "id": "1ca6db37-abce-4705-9784-e1b898174f00"
      },
      "source": [
        "#### d) Function to digest the text."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "digest_text <- function(text, n) {\n",
        "  toks <- tokenize_text(text)\n",
        "  build_ngram_table(toks, n)\n",
        "}"
      ],
      "metadata": {
        "id": "-ofZtY5wUH4Q"
      },
      "id": "-ofZtY5wUH4Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "53fff313-0f13-479b-94df-7588c19fdd3d",
      "metadata": {
        "id": "53fff313-0f13-479b-94df-7588c19fdd3d"
      },
      "source": [
        "#### e) Function to digest the url."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "library(httr)\n",
        "\n",
        "digest_url <- function(url, n) {\n",
        "  res <- httr::GET(url)\n",
        "  stopifnot(httr::http_error(res) == FALSE)\n",
        "  txt <- httr::content(res, as = \"text\", encoding = \"UTF-8\")\n",
        "  digest_text(txt, n)\n",
        "}"
      ],
      "metadata": {
        "id": "FHBXtYeIULNv"
      },
      "id": "FHBXtYeIULNv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "c4aa4e73-ee6f-4569-9a54-9d7f7eb3f80a",
      "metadata": {
        "id": "c4aa4e73-ee6f-4569-9a54-9d7f7eb3f80a"
      },
      "source": [
        "#### f) Function that gives random start."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_start <- function(tbl) {\n",
        "  keys <- ls(envir = tbl, all.names = TRUE)\n",
        "  if (length(keys) == 0) stop(\"No n-grams found — did you build the table?\")\n",
        "  sep <- attr(tbl, \"sep\", exact = TRUE)\n",
        "  strsplit(sample(keys, 1), sep, fixed = TRUE)[[1]]\n",
        "}"
      ],
      "metadata": {
        "id": "bo7WZll3UUqs"
      },
      "id": "bo7WZll3UUqs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "e998fb24-f2d6-41bc-a751-1f6accd3411f",
      "metadata": {
        "id": "e998fb24-f2d6-41bc-a751-1f6accd3411f"
      },
      "source": [
        "#### g) Function to predict the next word."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_next_word <- function(tbl, context) {\n",
        "  sep <- attr(tbl, \"sep\", exact = TRUE)\n",
        "  key <- paste(context, collapse = sep)\n",
        "  counts <- if (!is.null(tbl[[key]])) tbl[[key]] else integer(0)\n",
        "  if (length(counts) == 0) return(NA_character_)\n",
        "  sample(names(counts), size = 1, prob = as.numeric(counts))\n",
        "}"
      ],
      "metadata": {
        "id": "H8QUNM3aUVY6"
      },
      "id": "H8QUNM3aUVY6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "347f4002-4932-42c4-a4af-8689293a5857",
      "metadata": {
        "id": "347f4002-4932-42c4-a4af-8689293a5857"
      },
      "source": [
        "#### h) Function that puts everything together. Specify that if the user does not give a start word, then the random start will be used."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text <- function(tbl, start = NULL, length = 20L) {\n",
        "  n <- attr(tbl, \"n\", exact = TRUE)\n",
        "  if (is.null(n)) stop(\"Table missing 'n' attribute — build via build_ngram_table/digest_*.\")\n",
        "\n",
        "  # If user doesn’t give start words, pick a random (n-1)-gram\n",
        "  if (is.null(start) || length(start) != (n - 1L)) {\n",
        "    start <- random_start(tbl)\n",
        "  }\n",
        "\n",
        "  words <- start\n",
        "  for (i in seq_len(max(0L, length - length(start)))) {\n",
        "    ctx <- tail(words, n - 1L)\n",
        "    nx  <- predict_next_word(tbl, ctx)\n",
        "    if (is.na(nx)) break\n",
        "    words <- c(words, nx)\n",
        "  }\n",
        "\n",
        "  paste(words, collapse = \" \")\n",
        "}"
      ],
      "metadata": {
        "id": "_ASOPw9yUYut"
      },
      "id": "_ASOPw9yUYut",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "3b742c67-907c-4bc7-8df1-c84fa65a7554",
      "metadata": {
        "id": "3b742c67-907c-4bc7-8df1-c84fa65a7554"
      },
      "source": [
        "## Question 2\n",
        "#### For this question, set `seed=2025`.\n",
        "#### a) Test your model using a text file of [Grimm's Fairy Tails](https://www.gutenberg.org/cache/epub/2591/pg2591.txt)\n",
        "#### i) Using n=3, with the start word(s) \"the king\", with length=15.\n",
        "#### ii) Using n=3, with no start word, with length=15."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(2025)\n",
        "\n",
        "url <- \"https://www.gutenberg.org/cache/epub/2591/pg2591.txt\"\n",
        "tbl3 <- digest_url(url, n = 3)\n",
        "\n",
        "# (i) Using start words \"the king\", length = 15\n",
        "output_i <- generate_text(tbl3, start = c(\"the\", \"king\"), length = 15)\n",
        "cat(\"i) Start = 'the king' →\\n\", output_i, \"\\n\\n\")\n",
        "\n",
        "# (ii) No start word, random start, length = 15\n",
        "output_ii <- generate_text(tbl3, length = 15)\n",
        "cat(\"ii) Random start →\\n\", output_ii, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyKdO11FYW5R",
        "outputId": "fe325e7b-d09d-4b10-8d20-436deb498063"
      },
      "id": "dyKdO11FYW5R",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i) Start = 'the king' →\n",
            " the king has forbidden me to marry another husband am not i shall ride upon \n",
            "\n",
            "ii) Random start →\n",
            " song was over the lake and herself into her little daughter’s hand and was about \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e04b167-7f2c-4e0f-88e7-86ba5e8d74cc",
      "metadata": {
        "id": "0e04b167-7f2c-4e0f-88e7-86ba5e8d74cc"
      },
      "source": [
        "#### b) Test your model using a text file of [Ancient Armour and Weapons in Europe](https://www.gutenberg.org/cache/epub/46342/pg46342.txt)\n",
        "#### i) Using n=3, with the start word(s) \"the king\", with length=15.\n",
        "#### ii) Using n=3, with no start word, with length=15."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url <- \"https://www.gutenberg.org/cache/epub/46342/pg46342.txt\"\n",
        "tbl3 <- digest_url(url, n = 3)\n",
        "\n",
        "# (i) Using start words \"the king\", length = 15\n",
        "output_i <- generate_text(tbl3, start = c(\"the\", \"king\"), length = 15)\n",
        "cat(\"i) Start = 'the king' →\\n\", output_i, \"\\n\\n\")\n",
        "\n",
        "# (ii) No start word, random start, length = 15\n",
        "output_ii <- generate_text(tbl3, length = 15)\n",
        "cat(\"ii) Random start →\\n\", output_ii, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YnGAUyPZXc9",
        "outputId": "ca23acb0-5491-412f-e210-f04c5ddcdc5f"
      },
      "id": "4YnGAUyPZXc9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i) Start = 'the king' →\n",
            " the king is also defective you may demand a refund of any kind express or \n",
            "\n",
            "ii) Random start →\n",
            " mine his vigil of arms already cited and in token of the best illustration contributed \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25fb37ad-8e7c-4e62-afc0-ba46d46401fc",
      "metadata": {
        "id": "25fb37ad-8e7c-4e62-afc0-ba46d46401fc"
      },
      "source": [
        "#### c) Explain in 1-2 sentences the difference in content generated from each source.\n",
        "\n",
        "When you specify \"the king\" as the starting words, the model produces coherent fairy-tale continuations involving royal characters. With a random start, it begins from an arbitrary place in the corpus, so the generated text is more varied and sometimes less structured."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56e45972-f441-4d07-9073-fcddd6146cbd",
      "metadata": {
        "id": "56e45972-f441-4d07-9073-fcddd6146cbd"
      },
      "source": [
        "## Question 3\n",
        "#### a) What is a language learning model?\n",
        "\n",
        "A language learning model is a probability distribution over words. You put some input into the probability distribution, which is conditioning the probability distribution, and you get an output fom the probability distribution. It basically predicts the next word (token) given the previous words.\n",
        "\n",
        "\n",
        "#### b) Imagine the internet goes down and you can't run to your favorite language model for help. How do you run one locally?\n",
        "\n",
        "1. The raw text is split into tokens (usually words).\n",
        "2. The model uses previous tokens to form a probability distribution of possible next words.\n",
        "3. The model selects the next word based on these probabilities.\n",
        "4. The selected word is appended to the text and the process repeats to generate a full sentence."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b85a743b-f814-4a53-96e6-8bccb3d34ab8",
      "metadata": {
        "id": "b85a743b-f814-4a53-96e6-8bccb3d34ab8"
      },
      "source": [
        "## Question 4\n",
        "#### Explain what the following vocab words mean in the context of typing `mkdir project` into the command line. If the term doesn't apply to this command, give the definition and/or an example.\n",
        "| Term | Meaning |  \n",
        "|------|---------|\n",
        "| **Shell** | A program which lets you interact with all the functionality of a system (the operating system, in this context, though other systems have shells too); called a \"shell\" because its a shell around the O. |\n",
        "| **Terminal emulator** | A shell is something that sits between a user and an OS and the \"place\" the shell sits is the terminal emulator (HOSTS a shell). A terminal emulator can do special stuff with bytes returned by the shell to present effects, control, etc. |\n",
        "| **Process** | Something running on your computer |\n",
        "| **Signal** | Things we can send to processes to tell them to do something |\n",
        "| **Standard input** | Each process has these; they can read characters from the input and write to the output. |\n",
        "| **Standard output** | Each process has these; they can read characters from the input and write to the output. |\n",
        "| **Command line argument** | Things we pass to a process when we start it. |\n",
        "| **The environment** | All the stuff a process can see when its running; ok to imagine that when one process starts another, the child process sees all the same stuff as the parent. |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1332ff27-ca3f-4f7e-b4b9-07ead0358dd2",
      "metadata": {
        "id": "1332ff27-ca3f-4f7e-b4b9-07ead0358dd2"
      },
      "source": [
        "## Question 5\n",
        "#### Consider the following command `find . -iname \"*.R\" | xargs grep read_csv`.\n",
        "#### a) What are the programs?\n",
        "\n",
        "The programs are fine, xargs, and grep.\n",
        "\n",
        "#### b) Explain what this command is doing, part by part.\n",
        "\n",
        "find . -iname \"*.R\" : searches the current directory (.) and subdirectories for files whose names end in .R, case-sensitive.\n",
        "\n",
        "xargs grep read_csv : Runs grep read_csv on each of those files, searching inside them for the string \"read_csv\"\n",
        "\n",
        "Overall the command finds all R files in the project and prints the lines where read_csv is used."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69771ac7-865e-4d82-aa25-a39e7c1ab095",
      "metadata": {
        "id": "69771ac7-865e-4d82-aa25-a39e7c1ab095"
      },
      "source": [
        "## Question 6\n",
        "#### Install Docker on your machine. See [here](https://github.com/rjenki/BIOS512/blob/main/lecture18/docker_install.md) for instructions.\n",
        "#### a) Show the response when you run `docker run hello-world`.\n",
        "\n",
        "Hello from Docker!\n",
        "This message shows that your installation appears to be working correctly.\n",
        "\n",
        "To generate this message, Docker took the following steps:\n",
        " 1. The Docker client contacted the Docker daemon.\n",
        " 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub.\n",
        "    (arm64v8)\n",
        " 3. The Docker daemon created a new container from that image which runs the\n",
        "    executable that produces the output you are currently reading.\n",
        " 4. The Docker daemon streamed that output to the Docker client, which sent it\n",
        "    to your terminal.\n",
        "\n",
        "To try something more ambitious, you can run an Ubuntu container with:\n",
        " $ docker run -it ubuntu bash\n",
        "\n",
        "Share images, automate workflows, and more with a free Docker ID:\n",
        " https://hub.docker.com/\n",
        "\n",
        "For more examples and ideas, visit:\n",
        " https://docs.docker.com/get-started/\n",
        "\n",
        "#### b) Access Rstudio through a Docker container. Set your password and make sure your files show up on the Rstudio server. Type the command and the output you get below.\n",
        "\n",
        "talfayer@tals-MacBook-Pro ~ % docker run -e PASSWORD=mypassword -p 8787:8787 -v \"$PWD\":/home/rstudio -d rocker/rstudio\n",
        "\n",
        "Unable to find image 'rocker/rstudio:latest' locally\n",
        "latest: Pulling from rocker/rstudio\n",
        "b8a35db46e38: Pull complete\n",
        "2c9ba66d5dbe: Pull complete\n",
        "2034506aa72f: Pull complete\n",
        "bcce866b1806: Pull complete\n",
        "91ed5b86de88: Pull complete\n",
        "cc9c938c1f51: Pull complete\n",
        "5d246ec925db: Pull complete\n",
        "08e74fd5985d: Pull complete\n",
        "39038e16d1ba: Pull complete\n",
        "664fb1818bbb: Pull complete\n",
        "191985778909: Pull complete\n",
        "9c1a4a0706b7: Pull complete\n",
        "e2804bef35e8: Pull complete\n",
        "5b219f62ce36: Pull complete\n",
        "abd0190d83fb: Pull complete\n",
        "bc9245ceaac5: Pull complete\n",
        "a730ff463d58: Pull complete\n",
        "3665120d345d: Pull complete\n",
        "Digest: sha256:9f85211a666fb426081a6f5a01f9f9f51655262258419fa21e0ce38a5afc78d8\n",
        "Status: Downloaded newer image for rocker/rstudio:latest\n",
        "c82b406f84fdb79deae2e74e26efc2255a2822cf3d9cae00387c3fe966e455b8\n",
        "\n",
        "#### c) How do you log in to the RStudio server?\n",
        "\n",
        "using the username rstudio and the password you made in the docker run command."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "4.3.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}