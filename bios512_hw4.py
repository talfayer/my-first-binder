# -*- coding: utf-8 -*-
"""BIOS512_HW4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CiR5pa0PI8jlH1rI29ykytzAQ_69yNZv

# Homework 04
For questions 2-6, please use hw4.zip, which contains a data base of patient/hopsital data.

## Question 1
*For this question, you can either import these tables into R and do each join, or create the tables we expect to see in a Markdown cell.*   
Please see the tables below.
"""

library(tidyverse)

table_a <- tibble(
  SKU = c(102345, 104567, 108912, 109876, 112233),
  Fruit = c("Apple", "Orange", "Mango", "Blueberry", "Watermelon"),
  Color = c("Red", "Orange", "Yellow", "Blue", "Green"),
  Price = c(1.20, 1.40, 1.70, 3.50, 4.40),
  In_Stock = c("Yes", "Yes", "No", "Yes", "No")
)

table_b <- tibble(
  SKU = c(102345, 105432, 106789, 104567, 107654),
  Fruit = c("Apple", "Banana", "Grape", "Orange", "Pear"),
  Color = c("Red", "Yellow", "Purple", "Orange", "Green"),
  Sale_Price = c(1.00, 0.50, 2.00, 1.20, 1.10),
  Number_in_Stock = c(50, 120, 0, 75, 0)
)

"""What would the result be if you did...  
a) Left join  
  If you did table_a LEFT JOIN table_b, the result would keep all rows from table_a and add matching info from table_b.
  
b) Right join  
  If you did right join, it would keep all rows from table_b and add matching info from table_a.

c) Inner join
  Inner join would keep only matching rows, so in this case only SKU = 102345, 104567.  

d) Full join  
  Full join would keep all rows from both tables.

e) Semi join  
  Semi join would keep all rows from table_a that have a match in table_b but doesn't bring over the columns from table_b.

f) Anti join  
  Anti join would keep the rows from table_a that don't have a match in table_b.

## Question 2
Inspect the data sets in our database!  
a) Import them.  
b) Check out the columns and their variable types using one of R's tibble summary functions.
"""

demographics <- read_csv("demographics.csv")
full <- read_csv("full.csv")
hospitals <- read_csv("hospitals.csv")
patient_names <- read_csv("patient_names.csv")
treatment_info <- read_csv("treatment_info.csv")

glimpse(demographics)
glimpse(full)
glimpse(hospitals)
glimpse(patient_names)
glimpse(treatment_info)

"""## Question 3
Using the `full.csv` data set from our database, **pivot longer** by making all of the variables the same type. Use both `patient_ID` and `name` as ID variables. After pivoting, get a `tally` for number of observations per `patient ID`/`name`. (*Hint: We did this in lecture 5!*)  
"""

full <- read_csv("full.csv")
# Pivot
full_long <- full %>%
  pivot_longer(
    cols = -c(patient_id, name),
    names_to = "variable",
    values_to = "value",
    values_transform = as.character
  )
# Tally
obs_tally <- full_long %>%
  count(patient_id, name)

print(obs_tally)

"""## Question 4
Pivot longer by making one column per data type. Use both `patient_ID` and `name` as ID variables. After pivoting, get a `tally` for number of each type of observation per `patient ID`/`name`.  

**Helpful Hints:**  
1. You're performing 3 seperate pivots with careful column selection then joining them after!  
2. After each pivot, add the code below to create a unique row number:  
```
%>%
group_by(patient_id, name) %>%
  mutate(row = row_number()) %>%
  ungroup()
```
3. To greate the tally, add what is below after your grouping statement:   
```
%>%
summarise(
    n_chr  = sum(!is.na(value_chr)),
    n_num  = sum(!is.na(value_num)),
    n_date = sum(!is.na(value_date)),
    .groups = "drop"
```
"""

library(tidyverse)

full <- read_csv("full.csv")

# Pivot characters
full_chr <- full %>%
  pivot_longer(
    cols = c(gender, race, ethnicity, condition, treatment, department, hospital,
             patient_address, patient_city, patient_state),
    names_to = "variable_chr",
    values_to = "value_chr"
  ) %>%
  group_by(patient_id, name) %>%
  mutate(row = row_number()) %>%
  ungroup()

# Pivot numerics
full_num <- full %>%
  pivot_longer(
    cols = c(age, patient_zipcode),
    names_to = "variable_num",
    values_to = "value_num"
  ) %>%
  group_by(patient_id, name) %>%
  mutate(row = row_number()) %>%
  ungroup()

# Pivot dates
full_date <- full %>%
  pivot_longer(
    cols = c(admission_date, release_date),
    names_to = "variable_date",
    values_to = "value_date"
  ) %>%
  group_by(patient_id, name) %>%
  mutate(row = row_number()) %>%
  ungroup()

# Join all 3
full_long <- full_chr %>%
  left_join(full_num, by = c("patient_id", "name", "row")) %>%
  left_join(full_date, by = c("patient_id", "name", "row"))

# Tally
obs_tally <- full_long %>%
  group_by(patient_id, name) %>%
  summarise(
    n_chr  = sum(!is.na(value_chr)),
    n_num  = sum(!is.na(value_num)),
    n_date = sum(!is.na(value_date)),
    .groups = "drop"
  )

print(obs_tally)

"""## Question 5
Match patient names to the name of the hospital they were treated at.  
*Hint: You'll need `patient_names.csv` and `hospitals.csv`.*
"""

patients <- read_csv("patient_names.csv")
hospitals <- read_csv("hospitals.csv")

# Left join: keep all patients and add hospital info
patients_with_hospitals <- patients %>%
  left_join(hospitals %>% select(hospital_id, hospital_name), by = "hospital_id")

# Keep only patient name and hospital name
result <- patients_with_hospitals %>%
  select(name, hospital_name)

print(result)

"""## Question 6

Using joins, create a table that shows `patient_id`, `name`, `age`, `gender`, `condition`, and `treatment`.   
*Hint: You'll need `patient_names.csv`, `demographics.csv`, and `treatment_info.csv`.*
"""

patients <- read_csv("patient_names.csv")
demographics <- read_csv("demographics.csv")
treatment <- read_csv("treatment_info.csv")

# Join patients with demographics based on patient_id
patients_demo <- patients %>% left_join(demographics %>% select(patient_id, age, gender), by = "patient_id")
# Join the above with treatment_info based on condition_id
final_table <- patients_demo %>% left_join(treatment %>% select(condition_id, condition, treatment), by = "condition_id")
# Select the columns you want to show in final table after joining the three datasets
final_table <- final_table %>% select(patient_id, name, age, gender, condition, treatment)

print(final_table)

"""## Question 7
Let's revisit the NOFORC workshop.  
Below is what we completed in class on 9/9.  
**Please note: This contains the skimr library. Make sure you install that package! See the link for instructions: https://github.com/rjenki/BIOS512#adding-packages-to-installr-later.**  
"""

install.packages("skimr")

# Load UFO sightings data from a GitHub CSV
df <- read_csv("https://raw.githubusercontent.com/Vincent-Toups/bios512/refs/heads/main/nuforc_workshop/nuforc_sightings.csv")

# Read column names
names(df)

# Count the occurrences of each unique 'shape' value
unique_vals <- df$shape %>% table()

# Sort the counts of shapes in descending order and get the names
unique_vals %>% sort(decreasing = T) %>% names()

# Store column names in a vector
column_names <- names(df)

# Total number of rows in the dataset
n_total <- nrow(df)

# Loop over each column to get basic summary stats
for(col in column_names) {
  values <- df[[col]];        # Extract column
  n_na <- sum(is.na(values))  # Count number of NA values

  unique_vals <- values %>% table() %>% sort(decreasing = T)  # Count unique values and sort them by frequency
  n_unique <- length(unique_vals)

  cat(sprintf("%s:\n", col))  # Print column name
  cat(sprintf("\tnumber of NA values %d (%0.2f %%)\n", n_na, 100*n_na/n_total)) # Print number and percent of NA values
  if(n_unique < 150) cat(sprintf("\t\t%s\n", names(unique_vals) %>% paste(collapse=", "))) # If column has fewer than 150 unique values, print them all
  cat(sprintf("\tnumber of unique values %d (%0.2f %%)\n", length(unique_vals), # Print number and percent of unique values
    100*length(unique_vals)/n_total))
}

# Count number of reports per state and sort ascending
df %>% group_by(state) %>% tally() %>% arrange(n)

# Extract the 'occurred' column as a vector
df %>% pull(occurred)

# Helper function: nth(n) returns a function that extracts the nth element of a vector
nth <- function(n) function(a) a[n]

# Custom function to parse date strings by splitting on - / space : characters
parse_date <- function(s){
                          space_split <- s %>% str_split("[-/ :]")
                          tibble(d1 = Map(nth(1), space_split) %>% as.character(),
                                      d2 = Map(nth(2), space_split) %>% as.character(),
                                      d3 = Map(nth(3), space_split) %>% as.character(),
                                      d4 = Map(nth(4), space_split) %>% as.character(),
                                      d5 = Map(nth(5), space_split) %>% as.character())
                          }

# Apply the parsing function to the 'occurred' column
date_stuff <- parse_date(df %>% pull(occurred))
head(date_stuff, 10)

# Histogram of the second component of the split date (likely month)
ggplot (date_stuff, aes(d2))+ geom_bar() + labs(x = "Month", y = "Count")

# Install and load the skimr package for a nicer summary
library(skimr)

# Quick summary of the dataset
skim_output <- skimr::skim(df)

# Count occurrences for categorical columns
df %>% count(country, sort = TRUE)
df %>% count(state, sort = TRUE)
df %>% count(shape, sort = TRUE)

# Convert 'occurred' and 'reported' to proper date-time format using lubridate
df <- df %>%
  mutate(
  occurred = lubridate::mdy_hm(occurred, quiet = TRUE),
  reported = lubridate::mdy_hm(reported, quiet = TRUE)
  )

# Plot UFO sightings per year
df %>%
  filter(!is.na(occurred)) %>%
  count(year = lubridate::year(occurred)) %>%
  ggplot(aes(year, n)) +
  geom_line() +
    labs(title = "UFO Sightings per Year", x = "Year", y = "Number of Reports")

"""For the columns that have a low (relative to this dataset, which has ~150,000 observation) number of unique values, create a table that lists these unique values in ascending order."""

library(tidyverse)

# Select columns with low unique values (<150 for this example)
low_unique_cols <- df %>% select(state, country, shape, has_image)

# Create a list of sorted unique values for each column
unique_values_list <- map(low_unique_cols, ~ sort(unique(.)))

# Convert the list to a tidy table for viewing
unique_values_df <- enframe(unique_values_list, name = "column", value = "unique_values")

# View the result
print(unique_values_df)

"""## Question 8
Make a plot of number of UFO sightings by state (United States only). You can filter out states that only have one observation.
"""

library(tidyverse)

# Filter for USA and count sightings per state
state_counts <- df %>%
  filter(country == "USA") %>%        # Only US sightings
  group_by(state) %>%                 # Group by state
  tally(name = "sightings") %>%       # Count number of reports
  filter(sightings > 1) %>%           # Filter out states with only 1 sighting
  arrange(desc(sightings))            # Sort descending for plotting

# Plot as a bar chart
ggplot(state_counts, aes(x = reorder(state, sightings), y = sightings)) +
  geom_col(fill = "steelblue") +
  coord_flip() +  # Flip axes for readability
  labs(
    title = "Number of UFO Sightings by US State",
    x = "State",
    y = "Number of Sightings"
  ) +
  theme_minimal()